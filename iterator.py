import streamlit as st
import json
import uuid
import os
import openai
from dotenv import load_dotenv
from pydantic import BaseModel, create_model, ValidationError
from typing import List, Optional, Type

# --- 0. ç’°å¢ƒè¨­å®šèˆ‡ OpenAI åˆå§‹åŒ– ---
# è¼‰å…¥ .env æª”æ¡ˆä¸­çš„ç’°å¢ƒè®Šæ•¸
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦å­˜åœ¨
IS_API_KEY_VALID = OPENAI_API_KEY is not None and OPENAI_API_KEY.startswith("sk-")

if IS_API_KEY_VALID:
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
else:
    # å¦‚æœé‡‘é‘°ç„¡æ•ˆï¼Œå…ˆä¸å»ºç«‹ clientï¼Œç¨å¾Œåœ¨ UI ä¸­é¡¯ç¤ºéŒ¯èª¤
    client = None

# å®šç¾©æç¤ºè©èˆ‡æ–‡ä»¶ç¯„æœ¬çš„å­˜æª”è·¯å¾‘
SYSTEM_PROMPT_FILE_PATH = "system_prompt.txt"
USER_PROMPT_FILE_PATH = "user_prompt.txt"

# --- 1. æ ¸å¿ƒè¼”åŠ©å‡½å¼ ---

def render_fields_recursively(fields_dict, path_prefix):
    """
    éè¿´åœ°æ¸²æŸ“æ¬„ä½ã€‚
    """
    for field_id, field_data in list(fields_dict.items()):
        unique_key_prefix = f"{path_prefix}_{field_id}"
        cols = st.columns([5, 4, 3, 1])
        field_data['name'] = cols[0].text_input("æ¬„ä½åç¨±", value=field_data['name'], key=f"{unique_key_prefix}_name", label_visibility="collapsed")
        field_types_options = ['æ–‡å­—', 'æ—¥æœŸ', 'æ•¸å­—', 'ç‰©ä»¶ (Object)']
        field_data['type'] = cols[1].selectbox("æ¬„ä½é¡å‹", options=field_types_options, index=field_types_options.index(field_data['type']), key=f"{unique_key_prefix}_type", label_visibility="collapsed")
        is_object_type = field_data['type'] == 'ç‰©ä»¶ (Object)'
        field_data['allow_multiple'] = cols[2].checkbox("å…è¨±å¤šå€‹å€¼", value=field_data['allow_multiple'], key=f"{unique_key_prefix}_multi", help="å‹¾é¸å¾Œï¼Œæ­¤æ¬„ä½å°‡è¢«è¦–ç‚ºä¸€å€‹åˆ—è¡¨ (List)")
        if cols[3].button("âŒ", key=f"{unique_key_prefix}_del", help="åˆªé™¤æ­¤æ¬„ä½"):
            del fields_dict[field_id]
            st.rerun()
        if is_object_type:
            with st.container(border=True):
                st.markdown(f"ğŸ“„ **'{field_data['name'] or 'æœªå‘½åç‰©ä»¶'}'** çš„å­æ¬„ä½çµæ§‹")
                render_fields_recursively(field_data['sub_fields'], path_prefix=unique_key_prefix)
                if st.button("âŠ• æ–°å¢å­æ¬„ä½", key=f"{unique_key_prefix}_add_sub", use_container_width=True):
                    new_sub_field_id = str(uuid.uuid4())
                    field_data['sub_fields'][new_sub_field_id] = {'id': new_sub_field_id, 'name': '', 'type': 'æ–‡å­—', 'allow_multiple': False, 'sub_fields': {}}
                    st.rerun()

def generate_pydantic_model(model_name: str, schema_fields: dict) -> Type[BaseModel]:
    """
    å¾ UI å®šç¾©çš„ schema å­—å…¸ï¼Œéè¿´åœ°å‹•æ…‹ç”Ÿæˆä¸€å€‹ Pydantic æ¨¡å‹ã€‚
    """
    field_definitions = {}
    type_mapping = {'æ–‡å­—': str, 'æ—¥æœŸ': str, 'æ•¸å­—': int}
    for field_data in schema_fields.values():
        field_name = field_data.get('name')
        if not field_name: continue
        field_type_str = field_data['type']
        is_list = field_data.get('allow_multiple', False)
        if field_type_str == 'ç‰©ä»¶ (Object)':
            nested_model_name = f"{model_name}_{field_name}"
            field_type = generate_pydantic_model(nested_model_name, field_data['sub_fields'])
        else:
            field_type = type_mapping.get(field_type_str, str)
        final_type = List[field_type] if is_list else field_type
        field_definitions[field_name] = (Optional[final_type], None)
    return create_model(model_name, **field_definitions)

def render_results_dynamically(data: dict):
    """
    å„ªé›…åœ°å‘ˆç¾åˆ†æçµæœã€‚
    """
    for key, value in data.items():
        st.subheader(f"ğŸ·ï¸ {key}")
        if isinstance(value, list):
            if not value: st.write("_(ç„¡è³‡æ–™)_")
            elif value and isinstance(value[0], dict): st.dataframe(value, use_container_width=True)
            else:
                for item in value: st.markdown(f"- {item}")
        elif isinstance(value, dict):
            with st.container(border=True): render_results_dynamically(value)
        else: st.write(value)

def load_from_file(file_path):
    """
    å¦‚æœæª”æ¡ˆå­˜åœ¨å‰‡è®€å–ï¼Œå¦å‰‡å›å‚³ Noneã€‚
    """
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    return None

def save_to_file(file_path, content):
    """
    å°‡å…§å®¹å„²å­˜è‡³æª”æ¡ˆã€‚
    """
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    st.toast(f"å·²æˆåŠŸå„²å­˜è‡³ {os.path.basename(file_path)}ï¼")

# --- 2. é é¢è¨­å®šèˆ‡ç‹€æ…‹åˆå§‹åŒ– ---
st.set_page_config(page_title="æ•´åˆå¼æ³•å¾‹æ–‡ä»¶åˆ†æå™¨", layout="wide")
st.title("âš–ï¸ æ•´åˆå¼æ³•å¾‹æ–‡ä»¶åˆ†æå™¨")

if not IS_API_KEY_VALID:
    st.error("âš ï¸ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ OpenAI API é‡‘é‘°ï¼")
    st.info("è«‹åœ¨å°ˆæ¡ˆç›®éŒ„ä¸‹å»ºç«‹ä¸€å€‹åç‚º .env çš„æª”æ¡ˆï¼Œä¸¦åœ¨å…¶ä¸­åŠ å…¥æ‚¨çš„é‡‘é‘°ï¼š`OPENAI_API_KEY='sk-...'`")
    st.stop()

st.info("è«‹ä¾åºå®Œæˆè¨­å®šä¸¦è¼¸å…¥æ–‡ä»¶å…§å®¹ï¼Œç„¶å¾Œé»æ“Šæœ€ä¸‹æ–¹çš„æŒ‰éˆ•åŸ·è¡Œåˆ†æã€‚")

# åƒ…åœ¨ session_state ç¬¬ä¸€æ¬¡åˆå§‹åŒ–æ™‚åŸ·è¡Œ
if 'initialized' not in st.session_state:
    # å˜—è©¦å¾æª”æ¡ˆè¼‰å…¥ï¼Œå¦‚æœæª”æ¡ˆä¸å­˜åœ¨ï¼Œå‰‡ä½¿ç”¨é è¨­å€¼
    system_prompt_content = load_from_file(SYSTEM_PROMPT_FILE_PATH)
    user_prompt_content = load_from_file(USER_PROMPT_FILE_PATH)
    st.session_state.system_prompt = system_prompt_content
    st.session_state.user_prompt = user_prompt_content
    st.session_state.selected_model = "gpt-4.1" # æ‚¨çš„é è¨­æ¨¡å‹
    st.session_state.fields = {
        str(uuid.uuid4()): {'id': str(uuid.uuid4()), 'name': 'æ¡ˆè™Ÿ/æ¡ˆç”±', 'type': 'æ–‡å­—', 'allow_multiple': False, 'sub_fields': {}},
        str(uuid.uuid4()): {'id': str(uuid.uuid4()), 'name': 'åˆ¤æ±ºæ—¥æœŸ', 'type': 'æ—¥æœŸ', 'allow_multiple': False, 'sub_fields': {}},
        str(uuid.uuid4()): {'id': str(uuid.uuid4()), 'name': 'ç•¶äº‹äºº', 'type': 'æ–‡å­—', 'allow_multiple': True, 'sub_fields': {}},
        str(uuid.uuid4()): {'id': str(uuid.uuid4()), 'name': 'ä¸»æ–‡', 'type': 'æ–‡å­—', 'allow_multiple': False, 'sub_fields': {}},
        str(uuid.uuid4()): {'id': str(uuid.uuid4()), 'name': 'äº‹å¯¦æ¦‚è¦', 'type': 'æ–‡å­—', 'allow_multiple': False, 'sub_fields': {}},
        str(uuid.uuid4()): {'id': str(uuid.uuid4()), 'name': 'çˆ­é»', 'type': 'æ–‡å­—', 'allow_multiple': True, 'sub_fields': {}},
        str(uuid.uuid4()): {'id': str(uuid.uuid4()), 'name': 'åˆ¤æ±ºç†ç”±', 'type': 'æ–‡å­—', 'allow_multiple': False, 'sub_fields': {}},
    }
    st.session_state.initialized = True


# --- 3. ä¸»æ¸²æŸ“æµç¨‹ ---

# æ­¥é©Ÿ 1: ç³»çµ±èˆ‡æ¨¡å‹è¨­å®š
st.header("1. ç³»çµ±èˆ‡æ¨¡å‹è¨­å®š")
system_prompt_input = st.text_area("ç³»çµ±æç¤ºè© (System Prompt)", value=st.session_state.system_prompt, height=200, key="system_prompt_widget")
if st.button("ğŸ’¾ å„²å­˜æç¤ºè©", help=f"å°‡ç›®å‰çš„æç¤ºè©å„²å­˜è‡³ {SYSTEM_PROMPT_FILE_PATH}"):
    save_to_file(SYSTEM_PROMPT_FILE_PATH, system_prompt_input)
    st.session_state.system_prompt = system_prompt_input # æ›´æ–° session state

# PRESERVED: ä¿ç•™æ‚¨æŒ‡å®šçš„æ¨¡å‹åˆ—è¡¨
model_options = ["gpt-4.1", "gpt-4o", "o4-mini"]
st.session_state.selected_model = st.selectbox("é¸æ“‡ OpenAI æ¨¡å‹", options=model_options, index=model_options.index(st.session_state.selected_model))

# æ­¥é©Ÿ 2: è¼¸å‡ºçµæ§‹è¨­å®š
st.header("2. è¼¸å‡ºçµæ§‹è¨­å®š")
cols = st.columns([5, 4, 3, 1])
cols[0].markdown("**æ¬„ä½åç¨±**")
cols[1].markdown("**æ¬„ä½é¡å‹**")
cols[2].markdown("**å…è¨±å¤šå€‹å€¼**")
cols[3].markdown("**åˆªé™¤**")
render_fields_recursively(st.session_state.fields, path_prefix="root")
if st.button("â• æ–°å¢æ¬„ä½", use_container_width=True):
    new_field_id = str(uuid.uuid4())
    st.session_state.fields[new_field_id] = {'id': new_sub_field_id, 'name': '', 'type': 'æ–‡å­—', 'allow_multiple': False, 'sub_fields': {}}
    st.rerun()

# æ­¥é©Ÿ 3: æ³•å¾‹æ–‡ä»¶å…§æ–‡
st.header("3. æ³•å¾‹æ–‡ä»¶å…§æ–‡ (User Prompt)")
user_prompt_input = st.text_area("è²¼ä¸Šæ‚¨çš„æ³•å¾‹æ–‡ä»¶å…§å®¹ï¼š", height=300, value=st.session_state.user_prompt, key="user_prompt_widget")
if st.button("ğŸ’¾ å„²å­˜æ–‡ä»¶ç¯„æœ¬", help=f"å°‡ç›®å‰çš„æ–‡ä»¶å…§å®¹å„²å­˜ç‚ºé è¨­ç¯„æœ¬è‡³ {USER_PROMPT_FILE_PATH}"):
    save_to_file(USER_PROMPT_FILE_PATH, user_prompt_input)
    st.session_state.user_prompt = user_prompt_input # æ›´æ–° session state

st.divider()

# æ­¥é©Ÿ 4: åŸ·è¡Œèˆ‡è¼¸å‡º
if st.button("ğŸš€ åŸ·è¡Œåˆ†æ", type="primary", use_container_width=True):
    with st.spinner(f"æ­£åœ¨ä½¿ç”¨ `{st.session_state.selected_model}` æ¨¡å‹é€²è¡Œåˆ†æ..."):
        try:
            # å¾ session state ç²å–æœ€æ–°å€¼
            system_prompt = st.session_state.system_prompt
            raw_input_text = user_prompt_input # å¾ widget ç›´æ¥ç²å–ç•¶å‰å€¼
            
            DynamicPydanticModel = generate_pydantic_model('DynamicOutputModel', st.session_state.fields)
            pydantic_schema = json.dumps(DynamicPydanticModel.model_json_schema(), ensure_ascii=False, indent=2)
            final_prompt = f"""
            é€™æ˜¯éœ€è¦åˆ†æçš„æ³•å¾‹æ–‡ä»¶ï¼š
            ---æ–‡ä»¶é–‹å§‹---
            {raw_input_text}
            ---æ–‡ä»¶çµæŸ---

            è«‹æ ¹æ“šä¸Šè¿°æ–‡ä»¶å…§å®¹ï¼Œåš´æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON Schema æ ¼å¼æå–è³‡è¨Šä¸¦å›å‚³ã€‚
            ä½ çš„å›è¦†å¿…é ˆæ˜¯ä¸€å€‹æ ¼å¼å®Œå…¨æ­£ç¢ºçš„ JSON ç‰©ä»¶ï¼Œä¸è¦åŒ…å«ä»»ä½•é¡å¤–èªªæ˜æˆ– ```json ``` æ¨™ç±¤ã€‚

            JSON Schema:
            {pydantic_schema}
            """
            response = client.chat.completions.create(
                model=st.session_state.selected_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": final_prompt}
                ],
                response_format={"type": "json_object"}
            )
            api_response_str = response.choices[0].message.content
            st.session_state.raw_json_output = json.loads(api_response_str)
            validated_data = DynamicPydanticModel(**st.session_state.raw_json_output)
            st.session_state.validated_pydantic_object = validated_data
            st.success("åˆ†æå®Œæˆï¼")
        except openai.APIError as e: st.error(f"OpenAI API éŒ¯èª¤: {e}")
        except json.JSONDecodeError: st.error("API å›å‚³çš„ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚"); st.code(api_response_str, language="text")
        except ValidationError as e:
            st.error("è³‡æ–™é©—è­‰å¤±æ•—ï¼AI è¼¸å‡ºçš„ JSON èˆ‡æ‚¨çš„çµæ§‹å®šç¾©ä¸ç¬¦ã€‚")
            st.subheader("æ”¶åˆ°çš„ JSON è³‡æ–™:"); st.json(st.session_state.get('raw_json_output', {}))
            st.subheader("Pydantic é©—è­‰éŒ¯èª¤ç´°ç¯€:"); st.text(str(e))
        except Exception as e: st.error(f"ç™¼ç”Ÿé æœŸå¤–çš„éŒ¯èª¤: {e}")

if 'validated_pydantic_object' in st.session_state:
    st.header("4. åˆ†æè¼¸å‡ºçµæœ")
    render_results_dynamically(st.session_state.validated_pydantic_object.model_dump())
    with st.expander("é»æ­¤æŸ¥çœ‹åŸå§‹ JSON è¼¸å‡º"):
        st.json(st.session_state.get('raw_json_output', {}))
